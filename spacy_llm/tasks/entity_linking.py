import csv
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Type, Union

import jinja2
import spacy
from pydantic import BaseModel
from spacy.kb import InMemoryLookupKB
from spacy.language import Language
from spacy.pipeline import EntityLinker
from spacy.scorer import Scorer
from spacy.tokens import Doc, Span
from spacy.training import Example

from ..registry import registry
from ..ty import ExamplesConfigType
from .templates import read_template
from .util import SerializableTask

_DEFAULT_EL_TEMPLATE_V1 = read_template("entity_linking")
CANDIDATE_SELECTOR = Callable[[Span, Optional[Doc]], Dict[str, str]]


class EntityLinkingExample(BaseModel):
    text: str
    mentions_str: str
    mentions: List[str]
    entity_descriptions: List[List[str]]
    solutions: List[int]
    reasons: Optional[List[str]]


@registry.llm_misc("spacy.CandidateSelectorPipeline.v1")
class SpaCyPipelineCandidateLookup:
    """Callable generated by loading and wrapping a spaCy pipeline with a NEL component and a filled knowledge base."""

    def __init__(
        self,
        nlp_path: Union[Path, str],
        kb_path: Union[Path, str],
        desc_path: Union[Path, str],
    ):
        """
        Loads spaCy pipeline, knowledge base, entity descriptions.
        nlp_path (Union[Path, str]): Path to stored spaCy pipeline.
        kb_path (Union[Path, str]): Path to stored spaCy knowledge base.
        desc_path (Union[Path, str]): Path to .csv file with descriptions for entities. Has to have two columns
          with the first one being the entity ID, the second one being the description. The entity ID has to match with
          the entity ID in the stored knowledge base.
        """
        self._nlp = spacy.load(nlp_path)
        if "entity_linker" not in self._nlp.pipe_names:
            raise ValueError(
                f"'entity_linker' component has to be available in specified pipeline at {nlp_path}, but "
                f"isn't."
            )
        self._entity_linker: EntityLinker = self._nlp.get_pipe("entity_linker")
        self._kb = InMemoryLookupKB(
            vocab=self._nlp.vocab, entity_vector_length=self._nlp.vocab.vectors_length
        )
        self._kb.from_disk(kb_path)
        with open(desc_path) as csvfile:
            self._descs = {row[0]: row[1] for row in csv.reader(csvfile)}

    def __call__(self, mention: Span, _: Optional[Doc]) -> Dict[str, str]:
        return {
            cand.entity_: self._descs[cand.entity_]
            for cand in self._entity_linker.get_candidates(self._kb, mention)
        }

    def get_entity_description(self, entity_id: str) -> str:
        return self._descs[entity_id]


@registry.llm_tasks("spacy.EntityLinking.v1")
def make_entitylinking_task(
    candidate_selector: CANDIDATE_SELECTOR,
    template: str = _DEFAULT_EL_TEMPLATE_V1,
    examples: ExamplesConfigType = None,
):
    """EntityLinking.v1 task factory.

    template (str): Prompt template passed to the model.
    examples (Optional[Callable[[], Iterable[Any]]]): Optional callable that
        reads a file containing task examples for few-shot learning. If None is
        passed, then zero-shot learning will be used.
    candidate_selector (CANDIDATE_SELECTOR): Factory for a candidate selection callable
        returning candidates for a given Span and context.
    """
    raw_examples = examples() if callable(examples) else examples
    examples = (
        [EntityLinkingExample(**eg) for eg in raw_examples] if raw_examples else None
    )
    # Ensure there is a reason for every solution, even if it's empty. This makes templating easier.
    if examples:
        for example in examples:
            if example.reasons is None:
                example.reasons = [""] * len(example.solutions)
            elif len(example.reasons) < len(example.solutions):
                example.reasons.extend(
                    [""] * (len(example.solutions) - len(example.reasons))
                )

    return EntityLinkingTask(
        template=template, examples=examples, candidate_selector=candidate_selector
    )


class EntityLinkingTask(SerializableTask[EntityLinkingExample]):
    def __init__(
        self,
        candidate_selector: CANDIDATE_SELECTOR,
        template: str = _DEFAULT_EL_TEMPLATE_V1,
        examples: Optional[List[EntityLinkingExample]] = None,
    ):
        """Default entity linking task.

        template (str): Prompt template passed to the model.
        examples (Optional[Callable[[], Iterable[Any]]]): Optional callable that
            reads a file containing task examples for few-shot learning. If None is
            passed, then zero-shot learning will be used.
        candidate_selector (CANDIDATE_SELECTOR): Factory for a candidate selection callable
            returning candidates for a given Span and context.
        """
        self._template = template
        self._prompt_examples = examples or []
        self._candidate_selector = candidate_selector

    def initialize(
        self,
        get_examples: Callable[[], Iterable["Example"]],
        nlp: Language,
        n_prompt_examples: int = 0,
        **kwargs: Any,
    ) -> None:
        """Initializes prompt examples from Doc examples.
        get_examples (Callable[[], Iterable["Example"]]): Callable that provides examples
            for initialization.
        nlp (Language): Language instance.
        n_prompt_examples (int): How many prompt examples to infer from the provided Example objects.
            0 by default. Takes all examples if set to -1.
        """
        for eg in get_examples():
            if n_prompt_examples < 0 or len(self._prompt_examples) < n_prompt_examples:
                self._prompt_examples.append(self._create_prompt_example(eg))

    @property
    def prompt_template(self) -> str:
        return self._template

    def generate_prompts(self, docs: Iterable[Doc]) -> Iterable[str]:
        environment = jinja2.Environment()
        _template = environment.from_string(self._template)
        for doc in docs:
            prompt = _template.render(
                text=doc.text,
                examples=self._prompt_examples,
            )
            yield prompt

    def parse_responses(
        self, docs: Iterable[Doc], responses: Iterable[str]
    ) -> Iterable[Doc]:
        for doc, prompt_response in zip(docs, responses):
            parsed_response = [
                [pr_part.strip() for pr_part in pr.split(":")]
                for pr in prompt_response.replace("Lemmatized text:", "")
                .replace("'''", "")
                .strip()
                .split("\n")
            ]
            tokens = [token for token in doc]

            # If numbers of tokens recognized by spaCy and returned by LLM don't match, we don't attempt a partial
            # match.
            if len(tokens) != len(parsed_response):
                yield doc

            # Assign lemmas.
            for token, lemma_info in zip(tokens, parsed_response):
                if len(lemma_info) > 0:
                    token.lemma_ = lemma_info[1]

            yield doc

    def scorer(
        self,
        examples: Iterable[Example],
    ) -> Dict[str, Any]:
        """Scores lemmatization accuracy on provided examples.
        examples (Iterable[Example]): Examples to determine score against.
        """
        return Scorer.score_links(examples, negative_labels=[EntityLinker.NIL])

    @property
    def _cfg_keys(self) -> List[str]:
        return ["_template"]

    @property
    def _Example(self) -> Type[EntityLinkingExample]:
        return EntityLinkingExample

    def _create_prompt_example(self, example: Example) -> EntityLinkingExample:
        """Create a entity linking prompt example from a spaCy example."""
        # todo create prompt examples
        # - raise if len(ents) > 1, but no kb_id is set
        # - set reasons to ""
        """
        text: str
        mentions_str: str
        mentions: List[str]
        entity_descriptions: List[List[str]]
        solutions: List[int]
        reasons: Optional[List[str]]
        """
        mentions = [str(ent) for ent in example.reference.ents]
        mentions_str = ", ".join(  # noqa: F401, F841
            [f"*{mention}*" for mention in mentions]
        )

        entity_descriptions: List[List[str]] = [[]]  # noqa: F401, F841

        # Ensure that all entities have their knowledge base IDs set.
        # todo can we warn instead, at least when not in strict mode?
        n_ents = len(example.reference.ents)
        n_kb_ids = sum([ent.kb_id is not None for ent in example.reference.ents])
        if n_ents and n_ents != n_kb_ids:
            raise ValueError(
                f"Not all entities in this document have their knowledge base IDs set ({n_kb_ids} out of {n_ents}):\n"
                f"{example.reference}"
            )

        return EntityLinkingExample(
            text=example.reference.text,
            lemmas=[{t.text: t.lemma_} for t in example.reference],
        )
